## Methods

### Datasets

#### bioRxiv
1. Describe how bioRxiv was obtained
2. Describe metadata statistics on bioRxiv (number of preprints, number of preprints with multiple versions)

#### PubMed Central
1. Describe how PubMed central was obtained
2. Describe metadata statistics on PubMed central (number of articles, how many articles were processed

### Comparing Corpora
We used gensim [@raw:rehurek_lrec] (version 3.8.1) to preprocess the bioRxiv and PubMed Central corpora.
We removed the 337 gensim-provided stopwords.
Throughout our analysis we encountered non-word symbols (e.g., $\pm$), so we refer to words and symbols as tokens to avoid confusion.

Following the cleaning process, we calculated the frequency of every token shared between both corpora.
Because many tokens were unique to one set or the other and observed at low frequency, we used the union of the top 100 most frequent tokens from each corpus to compare them.
We generated a contingency table and calculated the odds ratio for each token.
Furthermore, we also calculated the 95% confidence interval for each odds ratio [@https://www.ncbi.nlm.nih.gov/books/NBK431098/].

### Visualizing the Preprint Landscape

#### Generate Document Representation
1. Describe how word2vec works
2. Talk about training word2vec on entire biorxiv repository
3. Discuss how to generate a document representation using word2vec model

#### Dimensionality Reduction of Document Embeddings
1. Explain how tSNE works (paragraph one)
2. Explain how PCA works  (paragraph two)
3. Discuss how words were mapped onto PC components via cosine similarity
4. ^ Explain cosine similarity

### Recommending Journals/ bioRxiv Audience Analysis
1. This title will update as analysis is completed
2. This section will describe how the above process is conducted
