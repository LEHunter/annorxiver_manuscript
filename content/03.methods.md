## Methods

### Datasets

#### bioRxiv
1. Describe how bioRxiv was obtained
2. Describe metadata statistics on bioRxiv (number of preprints, number of preprints with multiple versions)

#### PubMed Central
1. Describe how PubMed central was obtained
2. Describe metadata statistics on PubMed central (number of articles, how many articles were processed

### Comparing Corpora
The first step in lingusitic analysis is to clean up the text for ease of computation.
This clean up process consists of removing non-informative words (i.e., stop words) and converting words into their root form (i.e., lemmatization).
We used spaCy [@raw:honnibal2017spacy] to clean up the bioRxiv corpus and PubMed Central corpus.

Following the cleaning process, we calculated the frequency of each word in both corpora.
We generated a contingency table for each word as described in [@doi:10.1075/ijcl.6.1.05kil] (Table {@tbl:term-freq-contingency-table}).

| | bioRxiv | PubMed Central (PMC) | |
|---|---|---|---|
| w | a | b | a+b |
| $\neg$w | c | d | c+d |
| | a+c | b+d | a+b+c+d = Total |

Table: A contingency table for each word in bioRxiv and PubMed Central.
This table is designed for a given word w.
The first row depicts the frequency of w appearing in bioRxiv (a) and PubMed Central (b).
The second row depicts the frequency of all other words appearing in bioRxiv (c) and PubMed Central (d).
The total number of words can be found by adding (a,b,c,d) together as depicted in the bottom right.
{#tbl:term-freq-contingency-table}

Using the contingency table we performed a chi-squred test to see if there is a statistical difference between expected frequencies and observed frequencies.

We calculated the loglikelihood for each word to determine how well the contingency table fits with a chi-square distribution.
$$\begin{eqnarray}
LL &=& 2*(a\log(a) + b\log(b) + c\log(c) + d\log(d)	\nonumber \\
&-& (a+b)\log(a+b)-(a+c)\log(a+c)	\nonumber \\
&-& (b+d)\log(b+d)-(c+d)\log(c+d) \nonumber \\
&+& (a+b+c+d)\log(a+b+c+d)	\nonumber
\end{eqnarray}$$

We calculated the odds ratio between both corpora to determine how associated a word is with a given corpors compared to another.
$$OR=\frac{a*d}{b*c}$$
### Visualizing the Preprint Landscape

#### Generate Document Representation
1. Describe how word2vec works
2. Talk about training word2vec on entire biorxiv repository
3. Discuss how to generate a document representation using word2vec model

#### Dimensionality Reduction of Document Embeddings
1. Explain how tSNE works (paragraph one)
2. Explain how PCA works  (paragraph two)
3. Discuss how words were mapped onto PC components via cosine similarity
4. ^ Explain cosine similarity

### Recommending Journals/ bioRxiv Audience Analysis
1. This title will update as analysis is completed
2. This section will describe how the above process is conducted
