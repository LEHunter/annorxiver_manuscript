## Methods

### Datasets

#### bioRxiv
1. Describe how bioRxiv was obtained
2. Describe metadata statistics on bioRxiv (number of preprints, number of preprints with multiple versions)

#### PubMed Central
1. Describe how PubMed central was obtained
2. Describe metadata statistics on PubMed central (number of articles, how many articles were processed

### Comparing Corpora
The first step in linguistic analysis is to preprocess the text for ease of computation.
This step consists of removing non-informative words (i.e., stop words) as well as converting words into their root form (i.e., lemmatization).
Throughout our analysis we encountered symbols that aren't considered words (e.g., $\pm$), so we will refer to words and symbols as tokens to avoid confusion.
We used spaCy [@raw:honnibal2017spacy] to perform the above preprocessing tasks on the bioRxiv and PubMed Central corpora.

Following the cleaning process, we calculated the frequency of each token between both corpora.
Due to the large influx of unique tokens, we subsampled our analysis to use the union of the top 100 most frequent tokens between both corpora.
For each token we generated a contingency table as described in [@doi:10.1075/ijcl.6.1.05kil] (Table {@tbl:term-freq-contingency-table}).

| | corpus X | corpus Y | |
|---|---|---|---|
| w | a | b | a+b |
| $\neg$w | c | d | c+d |
| | a+c | b+d | a+b+c+d = Total |

Table: A contingency table for a given token that may appear in two corpora that are being compared.
Given a query token $w$, the first row depicts the frequency of $w$ appearing in corpus X (a) and corpus Y (b).
The second row depicts the frequency of all other tokens appearing in corpus X (c) and corpus Y (d).
The total number of tokens can be found by adding (a,b,c,d) together as depicted in the bottom right.
{#tbl:term-freq-contingency-table}

Once the contingency table has been created, we calculated the odds ratio  for a given token.
The odds ratio is defined as the fraction of the probability of a token $w$ appearing in corpus X divided by the probability of a token $w$ appearing in corpus Y.
Some tokens may only appear in one corpus and not another, which may result in a non-real number.
Our fix to this problem is to add a small epsilon ($1\mathrm{e}{-20}$) to every value in the contingency table.
Derivation for the odds ratio is provided here:

$$OR= \frac{\frac{a}{c}}{\frac{b}{d}}=\frac{a*d}{b*c}$$

The range of this ratio is $\[0, \infty\)$ with numbers greater than one implying that there is a strong association with a token appearing in corpus X compared to corpus Y.
Contrariwise, numbers less than one imply that there is a strong association with a token appearing in corpus Y rather than corpus X.

We calculated 95% confidence intervals for each odds ratio as mentioned in [@https://www.ncbi.nlm.nih.gov/books/NBK431098/].
These intervals were calculated by first taking the log of the odds ratio and then calculating the standard error of the contingency table.

$$SE(\log(OR)) = \sqrt{\frac{1}{a} + \frac{1}{b} + \frac{1}{c} + \frac{1}{d}}$$

Next we multiplied the standard error by the z-table's critical value (1.96).

$$\log(OR) \pm 1.96 * SE(\log(OR))$$

Lastly, we undid the log transform by taking the exp of the upper and lower bounds of the confidence interval.

$$\[\exp(\log(OR) - 1.96 * SE(\log(OR))), \exp(\log(OR) + 1.96 * SE(\log(OR)))\]$$

### Visualizing the Preprint Landscape

#### Generate Document Representation
1. Describe how word2vec works
2. Talk about training word2vec on entire biorxiv repository
3. Discuss how to generate a document representation using word2vec model

#### Dimensionality Reduction of Document Embeddings
1. Explain how tSNE works (paragraph one)
2. Explain how PCA works  (paragraph two)
3. Discuss how words were mapped onto PC components via cosine similarity
4. ^ Explain cosine similarity

### Recommending Journals/ bioRxiv Audience Analysis
1. This title will update as analysis is completed
2. This section will describe how the above process is conducted
